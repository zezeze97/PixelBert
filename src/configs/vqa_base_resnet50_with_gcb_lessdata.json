{
  "train_datasets": [
    {
      "name": "vqa",
      "txt": ["../vision_and_language_data/data/txt_db/vqa/vqa_k_trainval.jsonl",
              "../vision_and_language_data/data/txt_db/vqa/vg_k_trainval.jsonl"],
      "img": "../vision_and_language_data/data/vis_db/coco_train2014_val2014"
    }
  ],
  "val_datasets": [
    {
      "name": "vqa",
      "txt": "../vision_and_language_data/data/txt_db/vqa/vqa_k_test.jsonl",
      "img": "../vision_and_language_data/data/vis_db/coco_train2014_val2014"
    }
  ],
  "ans2label_path": "../vision_and_language_data/data/txt_db/vqa/trainval_ans2label.json",
  "max_txt_len": 20,
  "max_img_size": 768,
  "img_pixel_mean": [123.675, 116.28, 103.53],
  "img_pixel_std": [1.0, 1.0, 1.0],
  "img_input_format": "BGR",
  "max_n_example_per_group": 2,
  "model_config": "src/configs/base_model.json",
  "bert_weights_path": null,
  "e2e_weights_path":"../vision_and_language_data/pretrain_lessdata_output/ckpt/pretrained.pt",
  "tokenizer_dir": "../vision_and_language_data/data/pretrained/bert-base-uncased/",
  "output_dir": "/storage/vqa_default",
  "train_batch_size": 64,
  "val_batch_size": 2,
  "gradient_accumulation_steps": 4,
  "num_train_epochs": 10,
  "min_valid_steps": 100,
  "num_valid": 30,
  "learning_rate": 1e-4,
  "weight_decay": 1e-3,
  "decay": "linear",
  "optim": "adamw",
  "betas": [0.9, 0.98],
  "dropout": 0.1,
  "grad_norm": 2.0,
  "cnn_learning_rate": 1e-4,
  "cnn_weight_decay": 1e-3,
  "cnn_lr_decay": "linear",
  "seed":42,
  "fp16": 1,
  "classifier": "mlp",
  "cls_hidden_scale": 2,
  "num_labels": 3129
}
